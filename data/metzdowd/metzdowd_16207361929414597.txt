<PRE>John Denker wrote:
&gt;<i> On 09/29/2008 05:13 AM, IanG wrote:
</I>&gt;&gt;<i> My assumptions are:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>  * I trust no single source of Random Numbers.
</I>&gt;&gt;<i>  * I trust at least one source of all the sources.
</I>&gt;&gt;<i>  * no particular difficulty with lossy combination.
</I>&gt;<i> 
</I>&gt;<i> 
</I>&gt;&gt;<i> If I have N pools of entropy (all same size X) and I pool them
</I>&gt;&gt;<i> together with XOR, is that as good as it gets?
</I>&gt;<i> 
</I>&gt;<i> Yes.
</I>&gt;<i> 
</I>&gt;<i> The second assumption suffices to prove the result,
</I>&gt;<i> since (random bit) XOR (anything) is random.
</I>
unless you have a possible case where (say) for any given pool,
alternate bits are predictable; XORing all 'n' pools would still give a
maximum entropy of 50%, as the XOR of all 'n' predictable bits is
predictable.

using a hash which performs error diffusion, I would expect that 'n'
equal to 3 would give a suitable combined stream in that case (assuming
the 50% of random bits *are* random of course) 2 is possibly good
enough, but I would probably over-engineer at 3, in case one pool went
non-random.

---------------------------------------------------------------------
The Cryptography Mailing List
Unsubscribe by sending &quot;unsubscribe cryptography&quot; to <A HREF="http://www.metzdowd.com/mailman/listinfo/cryptography">majordomo at metzdowd.com</A>

</PRE>